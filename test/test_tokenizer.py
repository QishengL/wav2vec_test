from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
import torch
import torchaudio
from datasets import load_dataset, Audio
from phonemizer import phonemize
from phonemizer.separator import Separator
from phonemizer.backend import BACKENDS
def clean_phoneme_list(phoneme_list):
    """æ¸…ç†éŸ³ç´ åˆ—è¡¨ï¼Œç§»é™¤åŒä¸€å…ƒç´ å†…çš„ç©ºæ ¼"""
    cleaned_list = []
    
    for phoneme in phoneme_list:
        # ç§»é™¤åŒä¸€éŸ³ç´ å†…çš„ç©ºæ ¼
        cleaned_phoneme = phoneme.replace(" ", "")
        cleaned_list.append(cleaned_phoneme)
    
    return cleaned_list


# åŠ è½½æ¨¡å‹å’Œprocessor
model_path = "../weights/tk_100-xlsr-uzbase/checkpoint-2400"
model = Wav2Vec2ForCTC.from_pretrained(model_path)
processor = Wav2Vec2Processor.from_pretrained(model_path)

# å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
model.eval()
# "fsicoli/common_voice_22_0",
#"fixie-ai/common_voice_17_0",
# 2. åŠ è½½è¯„ä¼°æ•°æ®é›†
print("åŠ è½½æ•°æ®é›†ä¸­...")
raw_datasets = load_dataset(
    "fsicoli/common_voice_22_0",
    'tk',
    split='test',
    trust_remote_code=True,
    cache_dir="/mnt/storage/ldl_linguistics/datasets",
)

# ç¡®ä¿éŸ³é¢‘åˆ—æ˜¯Audioç±»å‹
raw_datasets = raw_datasets.cast_column("audio", Audio(sampling_rate=16000))

# 3. è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬
first_sample = raw_datasets[0]
print("\n" + "="*50)
print("ç¬¬ä¸€ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯:")
print("="*50)

additional_kwargs = {}
additional_kwargs["phonemizer_lang"] = 'tk'
gold_text = first_sample['sentence']
gold_ids = processor.tokenizer(gold_text, **additional_kwargs).input_ids

gold_decoded = processor.batch_decode(gold_ids)
# 4. æ‰“å°gold labelå’Œä¿¡æ¯
print(f"ğŸ“ åŸå§‹Gold Label: {gold_text}")
print(f"ğŸ”¤ Tokenizerå¤„ç†åGold: {gold_decoded}")
print(f"ğŸµ éŸ³é¢‘è·¯å¾„: {first_sample['audio']['path']}")
print(f"ğŸ“Š é‡‡æ ·ç‡: {first_sample['audio']['sampling_rate']}")
print(f"â±ï¸  éŸ³é¢‘é•¿åº¦: {len(first_sample['audio']['array'])} é‡‡æ ·ç‚¹")
print(f"â±ï¸  éŸ³é¢‘æ—¶é•¿: {len(first_sample['audio']['array']) / first_sample['audio']['sampling_rate']:.2f} ç§’")


#backend = BACKENDS["espeak"]("ba", language_switch="remove-flags")
#separator = Separator(phone=' ', word="", syllable="")

#phonemes = backend.phonemize(
#    [gold_text],
#    separator=separator,
#)
#phonemized_text = phonemes[0].strip()
#print(phonemized_text)

# é¢„å¤„ç†éŸ³é¢‘
inputs = processor(
    first_sample["audio"]["array"],
    sampling_rate=first_sample["audio"]["sampling_rate"],
    return_tensors="pt",
    padding=True
)
with torch.no_grad():
    logits = model(inputs.input_values).logits

 # è§£ç é¢„æµ‹ç»“æœ

    predicted_ids = torch.argmax(logits, dim=-1)
    pred_str = processor.batch_decode(predicted_ids)[0]
    #prediction = processor.batch_decode(predicted_ids)[0]
    #cleaned_gold = clean_phoneme_list(gold_decoded)
    #gold_str = ' '.join(cleaned_gold)
    print(f"ğŸ¤– æ¨¡å‹é¢„æµ‹: {pred_str}")

def clean_phoneme_list(phoneme_list):
    """æ¸…ç†éŸ³ç´ åˆ—è¡¨ï¼Œç§»é™¤åŒä¸€å…ƒç´ å†…çš„ç©ºæ ¼"""
    cleaned_list = []
    
    for phoneme in phoneme_list:
        # ç§»é™¤åŒä¸€éŸ³ç´ å†…çš„ç©ºæ ¼
        cleaned_phoneme = phoneme.replace(" ", "")
        cleaned_list.append(cleaned_phoneme)
    
    return cleaned_list

cleaned_gold = clean_phoneme_list(gold_decoded)
gold_str = ' '.join(cleaned_gold)

print(f"âœ… Gold Label: {gold_str}")
from evaluate import load
predictions = []
references = []
wer_metric = load("wer")
references.append(gold_str)
predictions.append(pred_str)
wer = wer_metric.compute(predictions=predictions, references=references)
print(f"æœ€ç»ˆWER: {wer:.4f}")